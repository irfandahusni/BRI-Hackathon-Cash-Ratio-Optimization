{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cash_echannel(cash_echannel_yesterday,cash_in_echannel_today,cash_out_echannel_today):\n",
    "    return cash_echannel_yesterday + cash_in_echannel_today + cash_out_echannel_today\n",
    "def cash_office_today(cash_office_yesterday,cash_in_office_today,cash_out_office_today) : \n",
    "    return cash_office_yesterday + cash_in_office_today + cash_out_office_today"
   ]
  },
 
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-fb9c95edea96>\", line 1, in <module>\n",
      "    data_desc = pd.read_csv('data_description.csv')\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 605, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 457, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 814, in __init__\n",
      "    self._engine = self._make_engine(self.engine)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1045, in _make_engine\n",
      "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1862, in __init__\n",
      "    self._open_handles(src, kwds)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1363, in _open_handles\n",
      "    storage_options=kwds.get(\"storage_options\", None),\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\common.py\", line 644, in get_handle\n",
      "    newline=\"\",\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data_description.csv'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"c:\\users\\microsoft user\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_description.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "data_desc = pd.read_csv('data_description.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "predict_len = 31\n",
    "test = test.iloc[0:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediksi Kas Kantor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(train.index).reshape((-1, 1))\n",
    "y = np.array(train.kas_kantor).reshape((-1,1))\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.plot(model.predict(x))\n",
    "plt.plot(np.array(train.kas_kantor).reshape((-1,1)))\n",
    "\n",
    "x_test = np.array(range(425,425+predict_len)).reshape(-1,1)\n",
    "x_test.shape\n",
    "                        \n",
    "y_pred_reg = model.predict(x_test)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.plot(x_test,y_pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_in = train.cash_in_echannel.iloc[:-len(test)].values\n",
    "test_data_in = train.cash_in_echannel.iloc[-len(test):].values\n",
    "train_data_out = train.cash_out_echannel.iloc[:-len(test)].values\n",
    "test_data_out = train.cash_out_echannel.iloc[-len(test):].values\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 50\n",
    "verbose = 1\n",
    "hidden_neuron1 = 31\n",
    "hidden_neuron2 = 31\n",
    "hidden_neuron3 = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq_in = train_data_in\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = len(test_data_in), len(test_data_in)\n",
    "# split into samples\n",
    "X_in, y_in = split_sequence(raw_seq_in, n_steps_in, n_steps_out)\n",
    "# define model\n",
    "model_in = Sequential()\n",
    "model_in.add(Dense(hidden_neuron1, activation='relu', input_dim=n_steps_in))\n",
    "model_in.add(Dense(hidden_neuron2, activation='relu', input_dim=n_steps_in))\n",
    "model_in.add(Dense(hidden_neuron3, activation='relu', input_dim=n_steps_in))\n",
    "model_in.add(Dense(n_steps_out))\n",
    "model_in.compile(loss='mse', optimizer='adam')\n",
    "es = keras.callbacks.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',  restore_best_weights=True)\n",
    "# fit model\n",
    "history = model_in.fit(X_in, y_in, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN and Validation LOSS\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale=1.4)  \n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history.history['loss'], color='r', linewidth=1, marker='d', markersize=7, label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], color='b',linewidth=1, marker='*',markersize=6, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation loss')\n",
    "legend = plt.legend(loc='upper right',prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction\n",
    "x_input = y_in\n",
    "# x_input = x_input.reshape((1, n_steps_in))\n",
    "yhat_in = model_in.predict(x_input, verbose=0)\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.plot(yhat_in[0])\n",
    "plt.plot(test_data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "\n",
    "# define input sequence\n",
    "raw_seq_out = train_data_out\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = len(test_data_out), len(test_data_out)\n",
    "# split into samples\n",
    "X_out, y_out = split_sequence(raw_seq_out, n_steps_in, n_steps_out)\n",
    "# define model\n",
    "model_out = Sequential()\n",
    "model_out.add(Dense(hidden_neuron1, activation='relu', input_dim=n_steps_in))\n",
    "model_out.add(Dense(hidden_neuron2, activation='relu', input_dim=n_steps_in))\n",
    "model_out.add(Dense(hidden_neuron3, activation='relu', input_dim=n_steps_in))\n",
    "model_out.add(Dense(n_steps_out))\n",
    "model_out.compile(loss='mse', optimizer='adam')\n",
    "es = keras.callbacks.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',  restore_best_weights=True)\n",
    "# fit model\n",
    "history = model_out.fit(X_out, y_out, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN and Validation LOSS\n",
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale=1.4)  \n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history.history['loss'], color='r', linewidth=1, marker='d', markersize=7, label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], color='b',linewidth=1, marker='*',markersize=6, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation loss')\n",
    "legend = plt.legend(loc='upper right',prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction\n",
    "x_input = y_out\n",
    "# x_input = x_input.reshape((1, n_steps_in))\n",
    "yhat_out = model_out.predict(x_input, verbose=0)\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.plot(yhat_out[0])\n",
    "plt.plot(test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecast Out Sample  \n",
    "x_input_in = test_data_in\n",
    "x_input_in = x_input_in.reshape((1, n_steps_in))\n",
    "yhat_in = model_in.predict(x_input_in, verbose=0)\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.plot(yhat_in[0])\n",
    "\n",
    "x_input_out = test_data_out\n",
    "x_input_out = x_input_out.reshape((1, n_steps_in))\n",
    "yhat_out = model_out.predict(x_input_out, verbose=0)\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.plot(yhat_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kas_ech_in = yhat_in[0]\n",
    "pred_kas_ech_out = yhat_out[0]\n",
    "train_cut= train[['cash_in_echannel', 'cash_out_echannel','kas_echannel']]\n",
    "df_pred = pd.DataFrame({'cash_in_echannel':pred_kas_ech_in,'cash_out_echannel':pred_kas_ech_out,'kas_echannel':0})\n",
    "train_cut = train_cut.append(df_pred).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(train_cut)):\n",
    "    train_cut.kas_echannel.iloc[i] = cash_echannel(train_cut.kas_echannel.iloc[i-1],train_cut.cash_in_echannel.iloc[i],train_cut.cash_out_echannel.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_office = y_pred_reg.reshape(31)\n",
    "subs_ech = train_cut.kas_echannel.iloc[-31:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['value'] = np.append(subs_office,subs_ech)\n",
    "submission.to_csv('subs_03.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
